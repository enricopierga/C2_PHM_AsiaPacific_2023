{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path_dataframes = \"../dataset/dataframes\"\n",
    "file_path = os.path.join(path_dataframes, \"test_data.pkl\")\n",
    "\n",
    "# Carica il DataFrame usando pd.read_pickle\n",
    "df_test = pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenuto del DataFrame:\n",
      "    TIME   P1   P2   P3   P4   P5   P6   P7  Case\n",
      "0  0.000  2.0  2.0  2.0  2.0  2.0  2.0  2.0   178\n",
      "1  0.001  2.0  2.0  2.0  2.0  2.0  2.0  2.0   178\n",
      "2  0.002  2.0  2.0  2.0  2.0  2.0  2.0  2.0   178\n",
      "3  0.003  2.0  2.0  2.0  2.0  2.0  2.0  2.0   178\n",
      "4  0.004  2.0  2.0  2.0  2.0  2.0  2.0  2.0   178\n",
      "\n",
      "Dimensione del DataFrame:\n",
      "(55246, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Contenuto del DataFrame:\")\n",
    "print(df_test.head())\n",
    "\n",
    "print(\"\\nDimensione del DataFrame:\")\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metriche nel dominio del tempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def time_domain_metrics(signal):\n",
    "    \"\"\"\n",
    "    Calcola le metriche nel dominio del tempo per un array 1D (signal).\n",
    "    Restituisce un dizionario con i valori calcolati.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    metrics[\"mean\"] = np.mean(signal)\n",
    "    metrics[\"median\"] = np.median(signal)\n",
    "    metrics[\"p25\"] = np.percentile(signal, 25)\n",
    "    metrics[\"p75\"] = np.percentile(signal, 75)\n",
    "    metrics[\"variance\"] = np.var(signal)\n",
    "    metrics[\"line_integral\"] = np.trapezoid(signal)  # approssima l'integrale\n",
    "    metrics[\"min\"] = np.min(signal)\n",
    "    metrics[\"max\"] = np.max(signal)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metriche nel dominio della frequenza (FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_domain_metrics(signal, sampling_rate=1000):\n",
    "    \"\"\"\n",
    "    Calcola alcune metriche spettrali (fft) per un array 1D (signal).\n",
    "    Restituisce un dizionario con i valori calcolati.\n",
    "    Puoi estendere questa funzione con SNR, SINAD, ecc.\n",
    "    \"\"\"\n",
    "    fft_result = np.fft.fft(signal)\n",
    "    freqs = np.fft.fftfreq(len(signal), d=1/sampling_rate)\n",
    "    \n",
    "    # Teniamo solo le frequenze positive (>0), escludendo la componente DC\n",
    "    positive_indices = np.where(freqs > 0)\n",
    "    fft_result = fft_result[positive_indices]\n",
    "    freqs = freqs[positive_indices]\n",
    "    \n",
    "    power_spectrum = np.abs(fft_result) ** 2\n",
    "    \n",
    "    # Esempio di metriche spettrali basilari\n",
    "    metrics = {}\n",
    "    metrics[\"peak_value\"] = np.max(power_spectrum)\n",
    "    metrics[\"peak_freq\"] = freqs[np.argmax(power_spectrum)]\n",
    "    metrics[\"sum_power_spectrum\"] = np.sum(power_spectrum)\n",
    "    metrics[\"std_power_spectrum\"] = np.std(power_spectrum)\n",
    "    \n",
    "    # (Facoltativo) Esempio di RMS nel dominio frequenziale\n",
    "    metrics[\"rms_freq\"] = np.sqrt(np.mean(power_spectrum))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione per aggregare un singolo Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_case(case_group, sampling_rate=1000):\n",
    "    \"\"\"\n",
    "    case_group: subset del DataFrame per un singolo Case\n",
    "    Ritorna un dizionario con le metriche calcolate per le colonne che iniziano con \"P\".\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    \n",
    "    # Consideriamo solo le colonne di segnale che iniziano con \"P\"\n",
    "    signal_columns = [col for col in case_group.columns if col.startswith(\"P\")]\n",
    "    \n",
    "    for col in signal_columns:\n",
    "        signal = case_group[col].values\n",
    "        \n",
    "        # Calcolo delle metriche nel dominio del tempo\n",
    "        td_metrics = time_domain_metrics(signal)\n",
    "        # Calcolo delle metriche nel dominio della frequenza\n",
    "        fd_metrics = frequency_domain_metrics(signal, sampling_rate=sampling_rate)\n",
    "        \n",
    "        # Inseriamo le metriche nel dizionario finale con un prefisso per ciascun segnale\n",
    "        for k, v in td_metrics.items():\n",
    "            result[f\"{col}_time_{k}\"] = v\n",
    "        for k, v in fd_metrics.items():\n",
    "            result[f\"{col}_freq_{k}\"] = v\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applica lâ€™aggregazione a tutto il DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Raggruppa per 'Case'\n",
    "grouped = df_test.groupby(\"Case\")\n",
    "\n",
    "# Lista dove salveremo i risultati (dizionari)\n",
    "aggregated_rows = []\n",
    "\n",
    "for case, group in grouped:\n",
    "    row_dict = aggregate_case(group, sampling_rate=1000)\n",
    "    # Aggiungi la colonna 'Case' in modo esplicito\n",
    "    row_dict[\"Case\"] = case\n",
    "    aggregated_rows.append(row_dict)\n",
    "\n",
    "# Costruisci il DataFrame finale\n",
    "df_aggregated = pd.DataFrame(aggregated_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risultato finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame aggregato:\n",
      "   P1_time_mean  P1_time_median  P1_time_p25  P1_time_p75  P1_time_variance  \\\n",
      "0      1.984422        1.965596     1.898145     2.057667          0.090330   \n",
      "1      1.984932        1.959335     1.893304     2.062764          0.093511   \n",
      "2      1.984972        1.959743     1.893367     2.058572          0.095046   \n",
      "3      1.985002        1.956308     1.893223     2.058859          0.095035   \n",
      "4      1.984954        1.959155     1.893371     2.058777          0.095023   \n",
      "\n",
      "   P1_time_line_integral  P1_time_min  P1_time_max  P1_freq_peak_value  \\\n",
      "0            2381.280903     0.561754     4.411926        10735.216150   \n",
      "1            2381.879996     0.453799     4.103312        10976.103217   \n",
      "2            2381.927644     0.436712     4.262760        11079.034425   \n",
      "3            2381.962902     0.442751     4.279393        11076.215410   \n",
      "4            2381.905815     0.437060     4.270896        11079.884937   \n",
      "\n",
      "   P1_freq_peak_freq  ...  P7_time_variance  P7_time_line_integral  \\\n",
      "0          62.447960  ...          0.301989            2366.205104   \n",
      "1          64.945878  ...          0.329252            2366.481721   \n",
      "2          64.945878  ...          0.332799            2359.785795   \n",
      "3          64.945878  ...          0.334852            2366.904783   \n",
      "4          64.945878  ...          0.328709            2366.746214   \n",
      "\n",
      "   P7_time_min  P7_time_max  P7_freq_peak_value  P7_freq_peak_freq  \\\n",
      "0    -0.003637     4.960276        34566.752154          62.447960   \n",
      "1    -0.002775     5.085864        46662.202025          64.945878   \n",
      "2    -0.005444     5.001972        42644.957266          64.945878   \n",
      "3    -0.004231     4.994317        42751.547033          64.945878   \n",
      "4    -0.004208     4.998432        43367.818082          64.945878   \n",
      "\n",
      "   P7_freq_sum_power_spectrum  P7_freq_std_power_spectrum  P7_freq_rms_freq  \\\n",
      "0               217794.811254                 2084.029330         19.052332   \n",
      "1               237456.962256                 2617.500682         19.893758   \n",
      "2               240014.559545                 2464.044767         20.000607   \n",
      "3               241495.688559                 2579.566737         20.062224   \n",
      "4               237065.315657                 2516.697697         19.877345   \n",
      "\n",
      "   Case  \n",
      "0   178  \n",
      "1   179  \n",
      "2   180  \n",
      "3   181  \n",
      "4   182  \n",
      "\n",
      "[5 rows x 92 columns]\n",
      "\n",
      "Dimensioni finali: (46, 92)\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame aggregato:\")\n",
    "print(df_aggregated.head())\n",
    "\n",
    "print(\"\\nDimensioni finali:\", df_aggregated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Le colonne sono: Index(['P1_time_mean', 'P1_time_median', 'P1_time_p25', 'P1_time_p75',\n",
      "       'P1_time_variance', 'P1_time_line_integral', 'P1_time_min',\n",
      "       'P1_time_max', 'P1_freq_peak_value', 'P1_freq_peak_freq',\n",
      "       'P1_freq_sum_power_spectrum', 'P1_freq_std_power_spectrum',\n",
      "       'P1_freq_rms_freq', 'P2_time_mean', 'P2_time_median', 'P2_time_p25',\n",
      "       'P2_time_p75', 'P2_time_variance', 'P2_time_line_integral',\n",
      "       'P2_time_min', 'P2_time_max', 'P2_freq_peak_value', 'P2_freq_peak_freq',\n",
      "       'P2_freq_sum_power_spectrum', 'P2_freq_std_power_spectrum',\n",
      "       'P2_freq_rms_freq', 'P3_time_mean', 'P3_time_median', 'P3_time_p25',\n",
      "       'P3_time_p75', 'P3_time_variance', 'P3_time_line_integral',\n",
      "       'P3_time_min', 'P3_time_max', 'P3_freq_peak_value', 'P3_freq_peak_freq',\n",
      "       'P3_freq_sum_power_spectrum', 'P3_freq_std_power_spectrum',\n",
      "       'P3_freq_rms_freq', 'P4_time_mean', 'P4_time_median', 'P4_time_p25',\n",
      "       'P4_time_p75', 'P4_time_variance', 'P4_time_line_integral',\n",
      "       'P4_time_min', 'P4_time_max', 'P4_freq_peak_value', 'P4_freq_peak_freq',\n",
      "       'P4_freq_sum_power_spectrum', 'P4_freq_std_power_spectrum',\n",
      "       'P4_freq_rms_freq', 'P5_time_mean', 'P5_time_median', 'P5_time_p25',\n",
      "       'P5_time_p75', 'P5_time_variance', 'P5_time_line_integral',\n",
      "       'P5_time_min', 'P5_time_max', 'P5_freq_peak_value', 'P5_freq_peak_freq',\n",
      "       'P5_freq_sum_power_spectrum', 'P5_freq_std_power_spectrum',\n",
      "       'P5_freq_rms_freq', 'P6_time_mean', 'P6_time_median', 'P6_time_p25',\n",
      "       'P6_time_p75', 'P6_time_variance', 'P6_time_line_integral',\n",
      "       'P6_time_min', 'P6_time_max', 'P6_freq_peak_value', 'P6_freq_peak_freq',\n",
      "       'P6_freq_sum_power_spectrum', 'P6_freq_std_power_spectrum',\n",
      "       'P6_freq_rms_freq', 'P7_time_mean', 'P7_time_median', 'P7_time_p25',\n",
      "       'P7_time_p75', 'P7_time_variance', 'P7_time_line_integral',\n",
      "       'P7_time_min', 'P7_time_max', 'P7_freq_peak_value', 'P7_freq_peak_freq',\n",
      "       'P7_freq_sum_power_spectrum', 'P7_freq_std_power_spectrum',\n",
      "       'P7_freq_rms_freq', 'Case'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLe colonne sono:\", df_aggregated.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esportazione in .csv e .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated.to_csv(\"../dataset/dataframes/test_data_aggregated.csv\", index=False)\n",
    "df_aggregated.to_pickle(\"../dataset/dataframes/test_data_aggregated.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
