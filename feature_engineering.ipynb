{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Caricamento dei file train_data_labeled.pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path_dataframes = \"dataset/dataframes\"\n",
    "file_path = os.path.join(path_dataframes, \"train_data_labeled.pkl\")\n",
    "\n",
    "# Carica il DataFrame usando pd.read_pickle\n",
    "df_train_labeled = pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenuto del DataFrame:\n",
      "    TIME   P1   P2   P3   P4   P5   P6   P7  Case  Spacecraft  ...  SV3  SV4  \\\n",
      "0  0.000  2.0  2.0  2.0  2.0  2.0  2.0  2.0     1           1  ...  100  100   \n",
      "1  0.001  2.0  2.0  2.0  2.0  2.0  2.0  2.0     1           1  ...  100  100   \n",
      "2  0.002  2.0  2.0  2.0  2.0  2.0  2.0  2.0     1           1  ...  100  100   \n",
      "3  0.003  2.0  2.0  2.0  2.0  2.0  2.0  2.0     1           1  ...  100  100   \n",
      "4  0.004  2.0  2.0  2.0  2.0  2.0  2.0  2.0     1           1  ...  100  100   \n",
      "\n",
      "   BP1  BP2  BP3 BP4 BP5 BP6 BP7 BV1  \n",
      "0   No   No   No  No  No  No  No  No  \n",
      "1   No   No   No  No  No  No  No  No  \n",
      "2   No   No   No  No  No  No  No  No  \n",
      "3   No   No   No  No  No  No  No  No  \n",
      "4   No   No   No  No  No  No  No  No  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Dimensione del DataFrame:\n",
      "(212577, 23)\n"
     ]
    }
   ],
   "source": [
    "print(\"Contenuto del DataFrame:\")\n",
    "print(df_train_labeled.head())\n",
    "\n",
    "print(\"\\nDimensione del DataFrame:\")\n",
    "print(df_train_labeled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metriche nel dominio del tempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def time_domain_metrics(signal):\n",
    "    \"\"\"\n",
    "    Calcola le metriche nel dominio del tempo per un array 1D (signal).\n",
    "    Restituisce un dizionario con i valori calcolati.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    metrics[\"mean\"] = np.mean(signal)\n",
    "    metrics[\"median\"] = np.median(signal)\n",
    "    metrics[\"p25\"] = np.percentile(signal, 25)\n",
    "    metrics[\"p75\"] = np.percentile(signal, 75)\n",
    "    metrics[\"variance\"] = np.var(signal)\n",
    "    metrics[\"line_integral\"] = np.trapezoid(signal)  # approssima l'integrale\n",
    "    metrics[\"min\"] = np.min(signal)\n",
    "    metrics[\"max\"] = np.max(signal)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metriche nel dominio della frequenza (FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_domain_metrics(signal, sampling_rate=1000):\n",
    "    \"\"\"\n",
    "    Calcola alcune metriche spettrali (fft) per un array 1D (signal).\n",
    "    Restituisce un dizionario con i valori calcolati.\n",
    "    Puoi estendere questa funzione con SNR, SINAD, ecc.\n",
    "    \"\"\"\n",
    "    fft_result = np.fft.fft(signal)\n",
    "    freqs = np.fft.fftfreq(len(signal), d=1/sampling_rate)\n",
    "    \n",
    "    # Teniamo solo le frequenze positive (>0), escludendo la componente DC\n",
    "    positive_indices = np.where(freqs > 0)\n",
    "    fft_result = fft_result[positive_indices]\n",
    "    freqs = freqs[positive_indices]\n",
    "    \n",
    "    power_spectrum = np.abs(fft_result) ** 2\n",
    "    \n",
    "    # Esempio di metriche spettrali basilari\n",
    "    metrics = {}\n",
    "    metrics[\"peak_value\"] = np.max(power_spectrum)\n",
    "    metrics[\"peak_freq\"] = freqs[np.argmax(power_spectrum)]\n",
    "    metrics[\"sum_power_spectrum\"] = np.sum(power_spectrum)\n",
    "    metrics[\"std_power_spectrum\"] = np.std(power_spectrum)\n",
    "    \n",
    "    # (Facoltativo) Esempio di RMS nel dominio frequenziale\n",
    "    metrics[\"rms_freq\"] = np.sqrt(np.mean(power_spectrum))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione per aggregare un singolo Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_case(case_group, sampling_rate=1000):\n",
    "    \"\"\"\n",
    "    case_group: subset del DataFrame per un singolo Case\n",
    "    Ritorna un dizionario con le metriche calcolate per P1..P7.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    \n",
    "    # Per le colonne che rimangono invariate all'interno dello stesso Case,\n",
    "    # prendiamo il valore dalla prima riga (o dall'ultima, è uguale).\n",
    "    # Aggiungile a piacimento (Spacecraft, Condition, ecc.)\n",
    "    columns_to_keep = [\"Spacecraft\", \"Condition\",\n",
    "                       \"SV1\", \"SV2\", \"SV3\", \"SV4\", \"BP1\", \"BP2\", \"BP3\", \n",
    "                       \"BP4\", \"BP5\", \"BP6\", \"BP7\", \"BV1\"]\n",
    "    for col in columns_to_keep:\n",
    "        if col in case_group.columns:\n",
    "            result[col] = case_group[col].iloc[0]\n",
    "    \n",
    "    # Per ogni colonna di segnale (P1..P7) calcoliamo le metriche\n",
    "    signal_columns = [col for col in case_group.columns \n",
    "                      if col.startswith(\"P\") and col not in columns_to_keep]\n",
    "    \n",
    "    for col in signal_columns:\n",
    "        signal = case_group[col].values\n",
    "        \n",
    "        # Calcolo metriche dominio del tempo\n",
    "        td_metrics = time_domain_metrics(signal)\n",
    "        # Calcolo metriche dominio della frequenza\n",
    "        fd_metrics = frequency_domain_metrics(signal, sampling_rate=sampling_rate)\n",
    "        \n",
    "        # Inseriamo le metriche nel dizionario finale con un prefisso\n",
    "        for k, v in td_metrics.items():\n",
    "            result[f\"{col}_time_{k}\"] = v\n",
    "        for k, v in fd_metrics.items():\n",
    "            result[f\"{col}_freq_{k}\"] = v\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applica l’aggregazione a tutto il DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Raggruppa per 'Case'\n",
    "grouped = df_train_labeled.groupby(\"Case\")\n",
    "\n",
    "# Lista dove salveremo i risultati (dizionari)\n",
    "aggregated_rows = []\n",
    "\n",
    "for case, group in grouped:\n",
    "    row_dict = aggregate_case(group, sampling_rate=1000)\n",
    "    # Aggiungi la colonna 'Case' in modo esplicito\n",
    "    row_dict[\"Case\"] = case\n",
    "    aggregated_rows.append(row_dict)\n",
    "\n",
    "# Costruisci il DataFrame finale\n",
    "df_aggregated = pd.DataFrame(aggregated_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risultato finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame aggregato:\n",
      "   Spacecraft Condition  SV1  SV2  SV3  SV4 BP1 BP2 BP3 BP4  ...  \\\n",
      "0           1    Normal  100  100  100  100  No  No  No  No  ...   \n",
      "1           1    Normal  100  100  100  100  No  No  No  No  ...   \n",
      "2           1    Normal  100  100  100  100  No  No  No  No  ...   \n",
      "3           1    Normal  100  100  100  100  No  No  No  No  ...   \n",
      "4           1    Normal  100  100  100  100  No  No  No  No  ...   \n",
      "\n",
      "  P7_time_variance P7_time_line_integral P7_time_min P7_time_max  \\\n",
      "0         0.329054           2366.012724   -0.003006    5.017115   \n",
      "1         0.335404           2366.376508   -0.003786    4.999330   \n",
      "2         0.353392           2368.725329   -0.007141    5.000936   \n",
      "3         0.321221           2365.701657   -0.002395    5.008294   \n",
      "4         0.324006           2366.740718   -0.002607    4.998044   \n",
      "\n",
      "   P7_freq_peak_value  P7_freq_peak_freq  P7_freq_sum_power_spectrum  \\\n",
      "0        47260.680479          64.945878               237314.084554   \n",
      "1        47662.864823          64.945878               241893.822061   \n",
      "2        46019.998152          64.945878               254866.442384   \n",
      "3        46367.986582          64.945878               231664.969366   \n",
      "4        46805.662115          64.945878               233673.009183   \n",
      "\n",
      "   P7_freq_std_power_spectrum  P7_freq_rms_freq  Case  \n",
      "0                 2632.685347         19.887772     1  \n",
      "1                 2688.225229         20.078754     2  \n",
      "2                 2743.060363         20.610129     3  \n",
      "3                 2565.994380         19.649638     4  \n",
      "4                 2592.227655         19.734615     5  \n",
      "\n",
      "[5 rows x 106 columns]\n",
      "\n",
      "Dimensioni finali: (177, 106)\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame aggregato:\")\n",
    "print(df_aggregated.head())\n",
    "\n",
    "\n",
    "print(\"\\nDimensioni finali:\", df_aggregated.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esportazione in .csv e .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated.to_csv(\"dataset/dataframes/train_data_aggregated.csv\", index=False)\n",
    "df_aggregated.to_pickle(\"dataset/dataframes/train_data_aggregated.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
